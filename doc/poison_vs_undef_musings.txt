Tradeoffs between poison and undef:

[ ] ANY proposal that uses short-circuit evaluation to remove overflow
taint (regardless of whether it is called poison, undef, or whatever)
appears to avoid the current problems with
simplify-the-control-flow-graph optimization.

[ ] As currently defined, the difference between poison and undef is
that an undef value, when read, may be assumed to be any value convenient for
optimization, while a poisoned value has a definite bit pattern
coupled with a requirement that it never be output.  (In effect,
poison requires the optimizer to do enough static analysis to
guarantee that a poison value can not be output.) 

[ ] In LLVM LangRef, why do they say

	%B= undef
	%C= or %B, %B

	can safely fold to:

	%C= undef

It is unclear if it _must_ safely fold to %C= undef, or does the compiler have
the _option_ of assuming that %B= -1, therefore %C=-1?  I know the manual says
a variable with an undef value can have a different value every time it is
read.  But it still seems like a singularity in the rules that the compiler is
_forbidden_ to assume that 2 undef values are the same when this would produce
a very useful optimization, such as the above %C.  There may be some value in
David and Nuno's suggestion that each time an undef value is generated, it is
a _different_ undef value, so the above '%C= undef' holds because both
operands of the or are the same undef value.  

[ ] David and Nuno's proposal seems like a highly simplified explanation of
the current LangRef's undef handling rules.  For example, they say, "if either
operand is undef, then the result is undef."  Do they indend to keep the
current undef handling rules (which seem superficially compatible with their
proposal), or do they see any differences in how undef is handled?

[ ] The current standard says, "poison values behave like undef values...".
Since the undef handling rules imply short-circuit handling for undef, is
applying short-circuit propogation of poison merely a clarification of the
existing rules?

[ ] This article by Dan Gohman notes that undef was not sufficiently
expressive to permit optimizations after overflow, and is "inconsistent", but
does not give any specific examples:

http://lists.cs.uiuc.edu/pipermail/llvmdev/2011-November/045730.html

[ ] The above 2011-November llvm-dev article by Dan also warns of
inconsistencies if select is considered to be like phi.  We need select to be
like phi.  What are these inconsistencies?

[ ] Dan noted a general inconsistency in optimization around nsw here:

http://lists.cs.uiuc.edu/pipermail/llvmdev/2011-December/046152.html

[ ] Sanjoy notes some interesting ideas in his 11/14/14 comments at
https://groups.google.com/forum/#!topic/llvm-dev/eQ7Fw2C_O9Q

In particular, undef requires _some_ valid bitpattern for the specified data
type, even though we don't necessarily know which one.  But poison does not==
thereby allowing optimizations like

	%a= INT_MAX;
	if ( %a < (%a+1) )  then { ... }

into

	%a= INT_MAX
	if ( true ) then { ... }

[ ] In his 23nov2014 post at
https://groups.google.com/forum/#!topic/llvm-dev/eQ7Fw2C_O9Q, 

David proposes having a 'vile' attribute to the select instruction, which
specifies if an unselected operand can propogate poison.  I don't see what we
gain from that in view of the opportunities afforded by
short-circuit-poison-removal in and and or operations.  

[ ] Andy Trick feels that speculative execution cannot be safely done on
operations with side effects (e.g. udiv).  I'm not sure how to evaluate his
claim right now. -- CAS 2015may14

http://lists.cs.uiuc.edu/pipermail/llvmdev/2011-December/046269.html

(end of file)

